# -*- coding: utf-8 -*-
"""app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-yIC6QbSuX3JmDAEMzKpXvRLfx0tTKPU
"""

# app.py
import streamlit as st
import cv2
import numpy as np
import math
from ultralytics import YOLO
import os
import time
import sys
import tempfile # To handle temporary video files
from collections import deque

# --- Page Configuration ---
st.set_page_config(
    page_title="Push-Up AI Coach",
    page_icon="üí™",
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- Constants and Configuration (from Sidebar) ---
st.sidebar.header("‚öôÔ∏è Configuration")

# --- Model & Detection ---
model_size_option = st.sidebar.selectbox(
    "Select YOLOv8 Pose Model Size ('s' recommended):",
    ("n", "s", "m", "l", "x"),
    index=1 # Default to 's'
)
model_name = f'yolov8{model_size_option}-pose.pt'

keypoint_confidence_threshold = st.sidebar.slider(
    "Keypoint Confidence Threshold:",
    min_value=0.1, max_value=0.9, value=0.5, step=0.05
)

# --- Push-up Form Thresholds ---
st.sidebar.subheader("üìê Form Thresholds (degrees)")
elbow_angle_up = st.sidebar.slider(
    "'UP' Elbow Angle Threshold:",
    min_value=140, max_value=180, value=160, step=5
)
elbow_angle_down = st.sidebar.slider(
    "'DOWN' Elbow Angle Threshold:",
    min_value=70, max_value=120, value=95, step=5
)
hip_angle_min = st.sidebar.slider(
    "Minimum 'Straight Body' Hip Angle:",
    min_value=130, max_value=170, value=150, step=5
)
hip_angle_max = st.sidebar.slider(
    "Maximum 'Straight Body' Hip Angle:",
    min_value=170, max_value=210, value=190, step=5
)

# --- Smoothing ---
smoothing_window_size = st.sidebar.slider(
    "Angle Smoothing Window (Frames):",
    min_value=1, max_value=10, value=3, step=1
)

# --- Visualization Settings ---
st.sidebar.subheader("üé® Visualization")
show_skeleton = st.sidebar.checkbox("Show Pose Skeleton", value=True)
show_angles = st.sidebar.checkbox("Show Live Angles", value=True)
show_info_panel = st.sidebar.checkbox("Show Info Panel", value=True)

# Colors (BGR Format)
CLR_BG = (20, 20, 20)
CLR_TEXT = (255, 255, 255)
CLR_GOOD = (0, 255, 0)
CLR_WARN = (0, 255, 255)
CLR_BAD = (0, 0, 255)
CLR_PRIMARY = (255, 100, 0)
CLR_SECONDARY = (200, 200, 200)
CLR_ELBOW = (255, 255, 0)
CLR_HIP = (0, 255, 255)

# Layout
INFO_PANEL_X = 10
INFO_PANEL_Y = 10
INFO_PANEL_WIDTH = 280
INFO_PANEL_ALPHA = 0.6
REP_COUNTER_POS = (INFO_PANEL_X + 15, INFO_PANEL_Y + 40)
STATE_POS = (INFO_PANEL_X + 15, INFO_PANEL_Y + 80)
FEEDBACK_POS = (INFO_PANEL_X + 15, INFO_PANEL_Y + 120)
SCORE_BAR_POS_X = INFO_PANEL_X + 15
SCORE_BAR_POS_Y = INFO_PANEL_Y + 160
SCORE_BAR_WIDTH = 30
SCORE_BAR_HEIGHT = 150
SCORE_TEXT_POS = (SCORE_BAR_POS_X + SCORE_BAR_WIDTH + 10, SCORE_BAR_POS_Y + SCORE_BAR_HEIGHT)


# --- Helper Functions ---

def calculate_angle(p1, p2, p3):
    """Calculates angle p1-p2-p3 (vertex at p2) in degrees."""
    if p1 is None or p2 is None or p3 is None: return None
    try:
        p1, p2, p3 = np.array(p1), np.array(p2), np.array(p3)
        v1, v2 = p1 - p2, p3 - p2
        dot_prod = np.dot(v1, v2)
        mag_v1, mag_v2 = np.linalg.norm(v1), np.linalg.norm(v2)
        if mag_v1 == 0 or mag_v2 == 0: return None
        cosine_angle = np.clip(dot_prod / (mag_v1 * mag_v2), -1.0, 1.0)
        return np.degrees(np.arccos(cosine_angle))
    except Exception: return None

def get_valid_coord(keypoints_data, idx, conf_threshold, confidences=None):
    """Safely retrieves keypoint coordinates if confidence is sufficient."""
    if keypoints_data.shape[0] <= idx: return None
    coords = keypoints_data[idx][:2].cpu().numpy()
    if confidences is not None and (len(confidences) <= idx or confidences[idx] < conf_threshold): return None
    if np.all(coords == 0): return None
    return coords

def draw_gradient_bar(img, x, y, w, h, percentage, min_clr, mid_clr, max_clr):
    """Draws a vertical gradient bar."""
    percentage = np.clip(percentage, 0, 100) / 100.0
    fill_h = int(h * percentage)
    fill_y = y + h - fill_h
    for i in range(fill_h):
        current_y = fill_y + i
        ratio = (h - (current_y - y)) / h
        if ratio < 0.5:
            local_ratio = ratio * 2
            r = int(min_clr[0] * (1 - local_ratio) + mid_clr[0] * local_ratio)
            g = int(min_clr[1] * (1 - local_ratio) + mid_clr[1] * local_ratio)
            b = int(min_clr[2] * (1 - local_ratio) + mid_clr[2] * local_ratio)
        else:
            local_ratio = (ratio - 0.5) * 2
            r = int(mid_clr[0] * (1 - local_ratio) + max_clr[0] * local_ratio)
            g = int(mid_clr[1] * (1 - local_ratio) + max_clr[1] * local_ratio)
            b = int(mid_clr[2] * (1 - local_ratio) + max_clr[2] * local_ratio)
        cv2.line(img, (x, current_y), (x + w, current_y), (b, g, r), 1)
    cv2.rectangle(img, (x, y), (x + w, y + h), CLR_SECONDARY, 1)


@st.cache_resource # Cache the model loading
def load_yolo_model(model_path):
    """Loads the YOLOv8 model."""
    try:
        model = YOLO(model_path)
        return model
    except Exception as e:
        st.error(f"Error loading YOLO model: {e}. Ensure the model name is correct and you have internet.")
        return None

def process_video(input_path, output_path, model):
    """Processes the video for push-up analysis."""
    cap = cv2.VideoCapture(input_path)
    if not cap.isOpened():
        st.error(f"Error: Could not open video file {input_path}")
        return None, None, None # Indicate error

    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    if fps is None or fps <= 0: fps = 30
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))

    # --- State Variables ---
    rep_counter = 0
    pushup_state = 'UP'
    last_rep_score = 0.0
    feedback_msg = "Starting Analysis"
    form_errors = []
    met_min_depth = False
    maintained_body_alignment = True
    elbow_angle_history = deque(maxlen=smoothing_window_size)
    hip_angle_history = deque(maxlen=smoothing_window_size)
    all_rep_scores = [] # Store scores for averaging

    # --- Progress Bar ---
    progress_bar = st.progress(0)
    status_text = st.empty() # Placeholder for status updates

    # --- Main Loop ---
    frame_num = 0
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        frame_num += 1

        # Update progress
        progress_percentage = int((frame_num / total_frames) * 100) if total_frames > 0 else 0
        progress_bar.progress(progress_percentage)
        status_text.text(f"Processing Frame {frame_num}/{total_frames if total_frames > 0 else 'N/A'} | Reps: {rep_counter} | Last Score: {last_rep_score:.0f}%")

        # --- Pose Estimation ---
        results = model(frame, stream=False, verbose=False)
        annotated_frame = frame.copy()

        # Overlay for Info Panel (optional based on checkbox)
        if show_info_panel:
            overlay = annotated_frame.copy()
            panel_height = SCORE_BAR_POS_Y + SCORE_BAR_HEIGHT + 40 # Calculate dynamic height
            cv2.rectangle(overlay, (INFO_PANEL_X, INFO_PANEL_Y),
                          (INFO_PANEL_X + INFO_PANEL_WIDTH, panel_height),
                          CLR_BG, -1)
            cv2.addWeighted(overlay, INFO_PANEL_ALPHA, annotated_frame, 1 - INFO_PANEL_ALPHA, 0, annotated_frame)

        # --- Keypoint & Angle Logic ---
        current_elbow_angle, current_hip_angle = None, None
        primary_elbow_coord, primary_hip_coord = None, None
        person_detected = False

        if results and results[0].keypoints and results[0].keypoints.data.numel() > 0:
             if results[0].keypoints.data.shape[0] > 0:
                person_detected = True
                keypoints = results[0].keypoints.data[0]
                confs = results[0].keypoints.conf[0] if results[0].keypoints.conf is not None else None

                kp_map = {}
                for name, idx in {'L_SHOULDER': 5, 'R_SHOULDER': 6, 'L_ELBOW': 7, 'R_ELBOW': 8,
                                  'L_WRIST': 9, 'R_WRIST': 10, 'L_HIP': 11, 'R_HIP': 12,
                                  'L_KNEE': 13, 'R_KNEE': 14}.items():
                    kp_map[name] = get_valid_coord(keypoints, idx, keypoint_confidence_threshold, confs)

                r_elbow = calculate_angle(kp_map['R_SHOULDER'], kp_map['R_ELBOW'], kp_map['R_WRIST'])
                l_elbow = calculate_angle(kp_map['L_SHOULDER'], kp_map['L_ELBOW'], kp_map['L_WRIST'])
                r_hip = calculate_angle(kp_map['R_SHOULDER'], kp_map['R_HIP'], kp_map['R_KNEE'])
                l_hip = calculate_angle(kp_map['L_SHOULDER'], kp_map['L_HIP'], kp_map['L_KNEE'])

                if r_elbow is not None: current_elbow_angle, primary_elbow_coord = r_elbow, kp_map['R_ELBOW']
                elif l_elbow is not None: current_elbow_angle, primary_elbow_coord = l_elbow, kp_map['L_ELBOW']

                if r_hip is not None: current_hip_angle, primary_hip_coord = r_hip, kp_map['R_HIP']
                elif l_hip is not None: current_hip_angle, primary_hip_coord = l_hip, kp_map['L_HIP']

                if current_elbow_angle is not None:
                    elbow_angle_history.append(current_elbow_angle)
                    current_elbow_angle = np.mean(elbow_angle_history)
                if current_hip_angle is not None:
                    hip_angle_history.append(current_hip_angle)
                    current_hip_angle = np.mean(hip_angle_history)

                # Draw Skeleton (optional)
                if show_skeleton:
                    annotated_frame = results[0].plot(img=annotated_frame, conf=False, boxes=False, line_width=2)

        # --- State Machine & Form Logic ---
        if person_detected and current_elbow_angle is not None and current_hip_angle is not None:
            if pushup_state == 'DOWN':
                if current_elbow_angle <= elbow_angle_down + 5: met_min_depth = True
                if not (hip_angle_min <= current_hip_angle <= hip_angle_max):
                    maintained_body_alignment = False
                    if "Align Hips" not in form_errors: form_errors.append("Align Hips")

            if pushup_state == 'UP' and current_elbow_angle < elbow_angle_down:
                pushup_state = 'DOWN'
                feedback_msg = "Going Down"
                met_min_depth, maintained_body_alignment = False, True
                form_errors = []
            elif pushup_state == 'DOWN' and current_elbow_angle > elbow_angle_up:
                pushup_state = 'UP'
                rep_counter += 1
                feedback_msg = f"Rep {rep_counter} Done!"
                score, total_criteria = 0, 3
                if met_min_depth: score += 1
                else: form_errors.append("Check Depth")
                if maintained_body_alignment: score += 1
                else: form_errors.append("Align Hips") # Error already added, but good to list
                score += 1 # Full extension
                last_rep_score = (score / total_criteria) * 100.0
                all_rep_scores.append(last_rep_score) # Store for avg
                if form_errors: feedback_msg += f" ({', '.join(form_errors)})"
                elif last_rep_score == 100: feedback_msg += " (Perfect!)"

            elif pushup_state == 'UP': feedback_msg = "Up Phase"
            elif pushup_state == 'DOWN':
                 feedback_msg = "Down Phase"
                 if not maintained_body_alignment and "Align Hips" not in form_errors:
                      form_errors.append("Align Hips")
                      feedback_msg = "Align Hips!"

        elif not person_detected: feedback_msg = "No Person Detected"
        else: feedback_msg = "Tracking..."

        # --- Visualization on Frame ---
        if show_info_panel:
            cv2.putText(annotated_frame, f"REPS: {rep_counter}", REP_COUNTER_POS, cv2.FONT_HERSHEY_SIMPLEX, 1.0, CLR_PRIMARY, 2, cv2.LINE_AA)
            cv2.putText(annotated_frame, f"STATE: {pushup_state}", STATE_POS, cv2.FONT_HERSHEY_SIMPLEX, 0.8, CLR_SECONDARY, 2, cv2.LINE_AA)
            cv2.putText(annotated_frame, "FEEDBACK:", (FEEDBACK_POS[0], FEEDBACK_POS[1]-5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, CLR_WARN, 1, cv2.LINE_AA)
            cv2.putText(annotated_frame, feedback_msg, FEEDBACK_POS, cv2.FONT_HERSHEY_SIMPLEX, 0.7, CLR_TEXT, 2, cv2.LINE_AA)
            cv2.putText(annotated_frame, "LAST REP SCORE:", (SCORE_BAR_POS_X, SCORE_BAR_POS_Y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, CLR_WARN, 1, cv2.LINE_AA)
            draw_gradient_bar(annotated_frame, SCORE_BAR_POS_X, SCORE_BAR_POS_Y, SCORE_BAR_WIDTH, SCORE_BAR_HEIGHT, last_rep_score, CLR_BAD, CLR_WARN, CLR_GOOD)
            cv2.putText(annotated_frame, f"{last_rep_score:.0f}%", SCORE_TEXT_POS, cv2.FONT_HERSHEY_SIMPLEX, 0.7, CLR_TEXT, 2, cv2.LINE_AA)

        if show_angles:
            if current_elbow_angle is not None and primary_elbow_coord is not None:
                cv2.putText(annotated_frame, f"{current_elbow_angle:.0f}", (int(primary_elbow_coord[0] + 10), int(primary_elbow_coord[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.7, CLR_ELBOW, 2, cv2.LINE_AA)
            if current_hip_angle is not None and primary_hip_coord is not None:
                 cv2.putText(annotated_frame, f"{current_hip_angle:.0f}", (int(primary_hip_coord[0] + 10), int(primary_hip_coord[1])), cv2.FONT_HERSHEY_SIMPLEX, 0.7, CLR_HIP, 2, cv2.LINE_AA)

        # Write Frame
        out.write(annotated_frame)

    # --- Cleanup ---
    cap.release()
    out.release()
    progress_bar.empty() # Remove progress bar
    status_text.text("Processing Complete!")

    # --- Calculate Final Stats ---
    average_score = np.mean(all_rep_scores) if all_rep_scores else 0

    return rep_counter, average_score, output_path


# --- Streamlit App UI ---
st.title("üí™ Push-Up AI Coach")
st.markdown("Upload a video of your push-ups and get feedback on your form and rep count.")
st.markdown("---")

uploaded_file = st.file_uploader("Choose a video file...", type=["mp4", "mov", "avi", "mkv"])

if uploaded_file is not None:
    st.success(f"File '{uploaded_file.name}' uploaded successfully!")

    # Load Model
    model = load_yolo_model(model_name)

    if model:
        # Use temporary files for processing
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tfile_in:
            tfile_in.write(uploaded_file.read())
            input_video_path = tfile_in.name

        # Create a unique name for the output temp file
        output_suffix = f"_analyzed_{int(time.time())}.mp4"
        with tempfile.NamedTemporaryFile(delete=False, suffix=output_suffix) as tfile_out:
            output_video_path = tfile_out.name

        st.info("Processing video... This may take a few minutes depending on video length and model size.")

        # Start processing in a spinner context
        with st.spinner('Analyzing your push-ups...'):
            total_reps, avg_score, processed_video_path = process_video(input_video_path, output_video_path, model)

        # Clean up input temp file
        os.unlink(input_video_path)

        if processed_video_path:
            st.balloons()
            st.header("üìä Analysis Results")

            col1, col2 = st.columns(2)
            with col1:
                st.metric(label="Total Reps Counted", value=f"{total_reps}")
            with col2:
                st.metric(label="Average Score / Rep", value=f"{avg_score:.1f}%")

            st.subheader("Watch Your Analyzed Video:")
            # Display the video
            video_file = open(processed_video_path, 'rb')
            video_bytes = video_file.read()
            st.video(video_bytes)
            video_file.close()

            # Offer download
            with open(processed_video_path, 'rb') as f:
                st.download_button(
                    label="Download Analyzed Video",
                    data=f,
                    file_name=f"analyzed_{uploaded_file.name}",
                    mime='video/mp4'
                )

            # Clean up output temp file after download button is generated
            # Note: Streamlit might keep the file open until script finishes or reruns
            # Adding a small delay might help ensure the file is available for download button generation
            # A more robust solution involves managing file state or using different temp file strategy if needed.
            try:
                # No explicit deletion here, let tempfile handle cleanup if possible,
                # or rely on OS temp cleaning. Explicitly unlinking might interfere
                # with the download button in some deployment scenarios.
                 pass
                 # os.unlink(processed_video_path) # Might cause issues with download button
            except Exception as e:
                 st.warning(f"Could not clean up temporary file {processed_video_path}: {e}")


        else:
            st.error("Video processing failed. Please check the video file or try again.")

    else:
        st.error("Failed to load the AI model. Cannot process the video.")

else:
    st.info("Please upload a video file to start the analysis.")

st.markdown("---")
st.markdown("Developed with Streamlit & YOLOv8.")